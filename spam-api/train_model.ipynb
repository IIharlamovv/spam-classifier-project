{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b231255e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Скачиваем необходимые данные NLTK\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9683a8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение модели...\n",
      "F1-Score (spam): 0.9209\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       966\n",
      "        spam       0.99      0.86      0.92       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.99      0.93      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "Confusion Matrix:\n",
      "[[965   1]\n",
      " [ 21 128]]\n",
      "Модель, векторизатор и препроцессор успешно сохранены в один файл!\n",
      "\n",
      "==================================================\n",
      "Демонстрация работы модели:\n",
      "==================================================\n",
      "Сообщение: Free entry in 2 a wkly comp to win FA Cup final tkts\n",
      "Предсказание: ham\n",
      "Вероятность спама: 0.4700\n",
      "Вероятность не спама: 0.5300\n",
      "Обработанный текст: free entri wkli comp win cup final tkt\n",
      "--------------------------------------------------\n",
      "Сообщение: Hey, are we still meeting for lunch tomorrow?\n",
      "Предсказание: ham\n",
      "Вероятность спама: 0.0000\n",
      "Вероятность не спама: 1.0000\n",
      "Обработанный текст: hey still meet lunch tomorrow\n",
      "--------------------------------------------------\n",
      "Сообщение: Congratulations! You've won a $1000 gift card. Click here to claim.\n",
      "Предсказание: spam\n",
      "Вероятность спама: 0.7603\n",
      "Вероятность не спама: 0.2397\n",
      "Обработанный текст: congratul 've 1000 gift card click claim\n",
      "--------------------------------------------------\n",
      "Сообщение: Ok, see you later then\n",
      "Предсказание: ham\n",
      "Вероятность спама: 0.0003\n",
      "Вероятность не спама: 0.9997\n",
      "Обработанный текст: see later\n",
      "--------------------------------------------------\n",
      "Сообщение: URGENT: Your bank account has been suspended. Verify your details now.\n",
      "Предсказание: ham\n",
      "Вероятность спама: 0.2630\n",
      "Вероятность не спама: 0.7370\n",
      "Обработанный текст: urgent bank account suspend verifi detail\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "def load_data(filepath):\n",
    "    df = pd.read_csv(filepath, encoding='latin-1')\n",
    "    df = df.rename(columns={'v1': 'target', 'v2': 'text'})\n",
    "    df = df[['target', 'text']]\n",
    "    return df\n",
    "\n",
    "# Препроцессинг текста\n",
    "class AdvancedTextPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "    def clean_text(self, text):\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        text = str(text).lower()\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "    \n",
    "    def tokenize_and_stem(self, text):\n",
    "        tokens = word_tokenize(text)\n",
    "        filtered_tokens = [\n",
    "            self.stemmer.stem(word) \n",
    "            for word in tokens \n",
    "            if word not in self.stop_words and len(word) > 2\n",
    "        ]\n",
    "        return filtered_tokens\n",
    "        \n",
    "    def preprocess(self, text):\n",
    "        cleaned_text = self.clean_text(text)\n",
    "        if not cleaned_text:\n",
    "            return \"\"\n",
    "        tokens = self.tokenize_and_stem(cleaned_text)\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "# Функция для обучения и сохранения модели\n",
    "def train_and_save_model():\n",
    "    # Загрузка данных\n",
    "    df = load_data('spam.zip')\n",
    "    \n",
    "    # Препроцессинг\n",
    "    preprocessor = AdvancedTextPreprocessor()\n",
    "    df['processed_text'] = df['text'].apply(preprocessor.preprocess)\n",
    "    \n",
    "    X = df['processed_text']\n",
    "    y = df['target']\n",
    "    \n",
    "    # Разделение данных\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Векторизация\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=3000, min_df=2, max_df=0.8,\n",
    "        ngram_range=(1, 3), stop_words='english'\n",
    "    )\n",
    "    \n",
    "    X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "    X_test_vectorized = vectorizer.transform(X_test)\n",
    "    \n",
    "    # Обучение модели\n",
    "    model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "    model.fit(X_train_vectorized, y_train)\n",
    "    \n",
    "    # Оценка модели\n",
    "    y_pred = model.predict(X_test_vectorized)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label='spam')\n",
    "    \n",
    "    print(f\"F1-Score (spam): {f1:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Визуализация матрицы ошибок\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['ham', 'spam'], \n",
    "                yticklabels=['ham', 'spam'])\n",
    "    plt.title('Confusion Matrix - Random Forest')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    # Сохранение модели, векторизатора и препроцессора в ОДИН файл\n",
    "    model_data = {\n",
    "        'model': model,\n",
    "        'vectorizer': vectorizer,\n",
    "        'preprocessor': preprocessor\n",
    "    }\n",
    "    joblib.dump(model_data, 'spam_classifier.joblib')\n",
    "    \n",
    "    print(\"Модель, векторизатор и препроцессор успешно сохранены в один файл!\")\n",
    "    \n",
    "    return model, vectorizer, preprocessor\n",
    "\n",
    "# Функция для загрузки модели и предсказания\n",
    "def load_model_and_predict(message):\n",
    "    # Загрузка ОДНОГО файла с моделью, векторизатором и препроцессором\n",
    "    try:\n",
    "        model_data = joblib.load('spam_classifier.joblib')\n",
    "        model = model_data['model']\n",
    "        vectorizer = model_data['vectorizer']\n",
    "        preprocessor = model_data['preprocessor']\n",
    "    except FileNotFoundError:\n",
    "        print(\"Файл модели не найден. Сначала обучите модель.\")\n",
    "        return None\n",
    "\n",
    "    # Предобработка и предсказание\n",
    "    processed_text = preprocessor.preprocess(message)\n",
    "    vectorized_text = vectorizer.transform([processed_text])\n",
    "    prediction = model.predict(vectorized_text)[0]\n",
    "    probability = model.predict_proba(vectorized_text)[0]\n",
    "    \n",
    "    result = {\n",
    "        'prediction': prediction,\n",
    "        'spam_probability': probability[1] if model.classes_[1] == 'spam' else probability[0],\n",
    "        'ham_probability': probability[0] if model.classes_[0] == 'ham' else probability[1],\n",
    "        'processed_text': processed_text\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Функция для демонстрации работы модели\n",
    "def demo_predictions():\n",
    "    test_messages = [\n",
    "        \"Free entry in 2 a wkly comp to win FA Cup final tkts\",\n",
    "        \"Hey, are we still meeting for lunch tomorrow?\",\n",
    "        \"Congratulations! You've won a $1000 gift card. Click here to claim.\",\n",
    "        \"Ok, see you later then\",\n",
    "        \"URGENT: Your bank account has been suspended. Verify your details now.\"\n",
    "    ]\n",
    "    \n",
    "    print(\"Демонстрация работы модели:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for msg in test_messages:\n",
    "        result = load_model_and_predict(msg)\n",
    "        if result:\n",
    "            print(f\"Сообщение: {msg}\")\n",
    "            print(f\"Предсказание: {result['prediction']}\")\n",
    "            print(f\"Вероятность спама: {result['spam_probability']:.4f}\")\n",
    "            print(f\"Вероятность не спама: {result['ham_probability']:.4f}\")\n",
    "            print(f\"Обработанный текст: {result['processed_text']}\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "# Основная функция\n",
    "if __name__ == \"__main__\":\n",
    "    # Обучаем и сохраняем модель (раскомментируйте для обучения)\n",
    "    print(\"Обучение модели...\")\n",
    "    model, vectorizer, preprocessor = train_and_save_model()\n",
    "    \n",
    "    # Демонстрация работы модели\n",
    "    demo_predictions()\n",
    "    \n",
    "    # Пример использования для одного сообщения\n",
    "    test_message = \"Free money! Claim your prize now!\"\n",
    "    result = load_model_and_predict(test_message)\n",
    "    \n",
    "    if result:\n",
    "        print(f\"\\nРезультат для тестового сообщения:\")\n",
    "        print(f\"Сообщение: {test_message}\")\n",
    "        print(f\"Предсказание: {result['prediction']}\")\n",
    "        print(f\"Вероятность спама: {result['spam_probability']:.4f}\")\n",
    "        print(f\"Вероятность не спама: {result['ham_probability']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda4a05e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
